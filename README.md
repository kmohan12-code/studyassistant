
# StudyAssistant with Google Gemini

This project is a web-based AI assistant that allows you to upload a PDF document and ask questions about its content. It uses a Retrieval-Augmented Generation (RAG) pipeline powered by Google's Gemini Pro model and LangChain to provide intelligent and context-aware answers.

---

## Features

* Interactive UI: A clean and user-friendly interface for uploading files and chatting.
* PDF Upload: Supports uploading PDF documents via button click or drag-and-drop.
* Document Processing: Extracts text from the PDF, splits it into manageable chunks, and creates a searchable vector index.
* Conversational Q\&A: Ask questions in natural language and receive answers generated by a powerful AI model based on the document's content.
* Powered by Gemini: Utilizes Google's `gemini-2.5-pro` for high-quality responses and `embedding-001` for text embeddings.

---

## Tech Stack

* **Backend:** Python, FastAPI
* **AI/ML:** LangChain, Google Generative AI (Gemini), FAISS (for vector storage)
* **Frontend:** HTML, CSS, JavaScript
* **PDF Processing:** PyPDF2

---

## How It Works

The application follows a Retrieval-Augmented Generation (RAG) architecture:

1. **PDF Processing:** When a user uploads a PDF, the backend extracts all text content.
2. **Text Chunking:** The extracted text is split into smaller, overlapping chunks to ensure semantic context is preserved.
3. **Vector Embedding:** Each text chunk is converted into a numerical vector representation (embedding) using Google's `models/embedding-001`.
4. **Vector Store:** These embeddings are stored in a local FAISS vector store, which allows for efficient similarity searches.
5. **Question Answering:**

   * The question is converted into an embedding.
   * The FAISS store is searched to find the text chunks with embeddings most similar to the question's embedding.
   * These relevant chunks (the context) and the original question are passed to the Gemini Pro model via a carefully crafted prompt.
   * The model generates a final, human-like answer based on the provided context.

---

## Setup and Installation

### Prerequisites

* Python 3.9+
* A Google API Key with the "Generative Language API" enabled (available from Google AI Studio).



### 2. Create a Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies

Create a `requirements.txt` file with the following:

```
fastapi
uvicorn[standard]
python-dotenv
google-generativeai
langchain-google-genai
langchain
pypdf2
faiss-cpu
```

Install everything:

```bash
pip install -r requirements.txt
```

### 4. Add Your API Key

Create a `.env` file in the main project folder and add:

```
GOOGLE_API_KEY="PASTE_YOUR_SECRET_API_KEY_HERE"
```

### 5. Run the App

```bash
uvicorn app:app --reload
```

Then open your browser and go to:
[http://127.0.0.1:8000](http://127.0.0.1:8000)

---

## Project Structure

```
.
├── app.py              # The heart of our backend server
├── templates/
│   └── index.html      # The main (and only) HTML page
├── static/
│   ├── style.css       # Makes everything look pretty
│   └── script.js       # Powers all the interactive features
├── .env                # Where your secret API key lives
├── requirements.txt    # A list of the Python tools we need
└── README.md           # You're reading it!
```

---

